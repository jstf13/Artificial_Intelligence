{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from MountainCarEnv import MountainCarEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Asigna el ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MountainCarEnv(render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epsilon Greedy Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(state, Q, epsilon=0.1):\n",
    "    explore = np.random.binomial(1, epsilon)\n",
    "    if explore:\n",
    "        action = env.action_space.sample()\n",
    "    else:\n",
    "        action = np.argmax(Q[state])\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Policy Optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_policy(state, Q):\n",
    "    action = np.argmax(Q[state])\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de posición y velocidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.2, -1. , -0.8, -0.6, -0.4, -0.2,  0. ,  0.2,  0.4,  0.6])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_space = np.linspace(-1.2, 0.6, 10)\n",
    "vel_space = np.linspace(-0.07, 0.07, 10)\n",
    "pos_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discretización de estados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state(obs):\n",
    "    pos, vel = obs\n",
    "    pos_bin = np.digitize(pos, pos_space)\n",
    "    vel_bin = np.digitize(vel, vel_space)\n",
    "    return pos_bin, vel_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = get_state(np.array([-0.4, 0.2]))\n",
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = list(range(env.action_space.n))\n",
    "actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inicialización de Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1001, 101, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episodios = 1000\n",
    "Q = np.zeros((episodios+1, 101, 3))\n",
    "Q.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento de Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode #0: Reward = -500, Best reward = -500, Position = 4, Epsilon = 0.23979400086720376, Alpha = 0.5\n",
      "Position without discretizing = -0.49097880721092224\n",
      "Episode #1: Reward = -500, Best reward = -500, Position = 4, Epsilon = 0.20969100130080565, Alpha = 0.5\n",
      "Position without discretizing = -0.5168740749359131\n",
      "Episode #2: Reward = -500, Best reward = -500, Position = 4, Epsilon = 0.19208187539523755, Alpha = 0.5\n",
      "Position without discretizing = -0.5217592716217041\n",
      "Episode #3: Reward = -500, Best reward = -500, Position = 4, Epsilon = 0.17958800173440753, Alpha = 0.5\n",
      "Position without discretizing = -0.5652530193328857\n",
      "Episode #4: Reward = -500, Best reward = -500, Position = 4, Epsilon = 0.1698970004336019, Alpha = 0.5\n",
      "Position without discretizing = -0.7823109030723572\n",
      "Episode #5: Reward = -500, Best reward = -500, Position = 4, Epsilon = 0.1619788758288394, Alpha = 0.5\n",
      "Position without discretizing = -0.5933903455734253\n",
      "Episode #6: Reward = -500, Best reward = -500, Position = 4, Epsilon = 0.1552841968657781, Alpha = 0.5\n",
      "Position without discretizing = -0.9969329833984375\n",
      "Episode #7: Reward = -500, Best reward = -500, Position = 4, Epsilon = 0.1494850021680094, Alpha = 0.5\n",
      "Position without discretizing = -1.1885249614715576\n",
      "Episode #8: Reward = -500, Best reward = -500, Position = 7, Epsilon = 0.14436974992327128, Alpha = 0.5\n",
      "Position without discretizing = 0.10111052542924881\n",
      "Episode #9: Reward = -500, Best reward = -500, Position = 7, Epsilon = 0.13979400086720375, Alpha = 0.5\n",
      "Position without discretizing = -0.3100298047065735\n",
      "Episode #10: Reward = -500, Best reward = -500, Position = 7, Epsilon = 0.13565473235138126, Alpha = 0.5\n",
      "Position without discretizing = -0.25652551651000977\n",
      "Episode #11: Reward = -500, Best reward = -500, Position = 7, Epsilon = 0.1318758762624413, Alpha = 0.5\n",
      "Position without discretizing = -0.2110704928636551\n",
      "Episode #12: Reward = -500, Best reward = -500, Position = 7, Epsilon = 0.12839966563652008, Alpha = 0.5\n",
      "Position without discretizing = -0.5297174453735352\n",
      "Episode #13: Reward = -500, Best reward = -500, Position = 7, Epsilon = 0.12518119729937996, Alpha = 0.5\n",
      "Position without discretizing = -0.22503317892551422\n",
      "Episode #14: Reward = -500, Best reward = -500, Position = 7, Epsilon = 0.12218487496163564, Alpha = 0.5\n",
      "Position without discretizing = -1.0127702951431274\n",
      "Episode #15: Reward = -390, Best reward = -390, Position = 9, Epsilon = 0.1193820026016113, Alpha = 0.5\n",
      "Position without discretizing = 0.5032932758331299\n",
      "Episode #16: Reward = -500, Best reward = -390, Position = 9, Epsilon = 0.11674910872937637, Alpha = 0.5\n",
      "Position without discretizing = -0.273999959230423\n",
      "Episode #17: Reward = -500, Best reward = -390, Position = 9, Epsilon = 0.11426675035687316, Alpha = 0.5\n",
      "Position without discretizing = -0.12053116410970688\n",
      "Episode #18: Reward = -500, Best reward = -390, Position = 9, Epsilon = 0.11191864077192087, Alpha = 0.5\n",
      "Position without discretizing = 0.23030580580234528\n",
      "Episode #19: Reward = -500, Best reward = -390, Position = 9, Epsilon = 0.10969100130080565, Alpha = 0.5\n",
      "Position without discretizing = -0.6458958983421326\n",
      "Episode #20: Reward = -500, Best reward = -390, Position = 9, Epsilon = 0.10757207139381185, Alpha = 0.5\n",
      "Position without discretizing = -0.7649430632591248\n",
      "Episode #21: Reward = -432, Best reward = -390, Position = 9, Epsilon = 0.10555173278498314, Alpha = 0.5\n",
      "Position without discretizing = 0.5017802715301514\n",
      "Episode #22: Reward = -500, Best reward = -390, Position = 9, Epsilon = 0.10362121726544447, Alpha = 0.5\n",
      "Position without discretizing = 0.0417378805577755\n",
      "Episode #23: Reward = -500, Best reward = -390, Position = 9, Epsilon = 0.10177287669604317, Alpha = 0.5\n",
      "Position without discretizing = -0.5164017081260681\n",
      "Episode #24: Reward = -500, Best reward = -390, Position = 9, Epsilon = 0.1, Alpha = 0.5\n",
      "Position without discretizing = -0.01241601537913084\n",
      "Episode #25: Reward = -500, Best reward = -390, Position = 9, Epsilon = 0.09829666607012197, Alpha = 0.5\n",
      "Position without discretizing = -0.7057719826698303\n",
      "Episode #26: Reward = -500, Best reward = -390, Position = 9, Epsilon = 0.09665762445130503, Alpha = 0.5\n",
      "Position without discretizing = 0.3806329667568207\n",
      "Episode #27: Reward = -500, Best reward = -390, Position = 9, Epsilon = 0.09507819773298185, Alpha = 0.5\n",
      "Position without discretizing = -0.5397307872772217\n",
      "Episode #28: Reward = -500, Best reward = -390, Position = 9, Epsilon = 0.09355420107730816, Alpha = 0.5\n",
      "Position without discretizing = -0.6481215953826904\n",
      "Episode #29: Reward = -500, Best reward = -390, Position = 9, Epsilon = 0.09208187539523753, Alpha = 0.5\n",
      "Position without discretizing = -0.8699420690536499\n",
      "Episode #30: Reward = -500, Best reward = -390, Position = 9, Epsilon = 0.0906578314837765, Alpha = 0.5\n",
      "Position without discretizing = -0.5812809467315674\n",
      "Episode #31: Reward = -500, Best reward = -390, Position = 9, Epsilon = 0.08927900303521318, Alpha = 0.5\n",
      "Position without discretizing = -0.5921244621276855\n",
      "Episode #32: Reward = -500, Best reward = -390, Position = 9, Epsilon = 0.08794260687941502, Alpha = 0.5\n",
      "Position without discretizing = -0.5157221555709839\n",
      "Episode #33: Reward = -500, Best reward = -390, Position = 9, Epsilon = 0.08664610916297825, Alpha = 0.5\n",
      "Position without discretizing = -0.5525451898574829\n",
      "Episode #34: Reward = -500, Best reward = -390, Position = 9, Epsilon = 0.08538719643217621, Alpha = 0.5\n",
      "Position without discretizing = -0.523006796836853\n",
      "Episode #35: Reward = -500, Best reward = -390, Position = 9, Epsilon = 0.08416375079047504, Alpha = 0.5\n",
      "Position without discretizing = -0.4680008888244629\n",
      "Episode #36: Reward = -500, Best reward = -390, Position = 9, Epsilon = 0.08297382846050427, Alpha = 0.5\n",
      "Position without discretizing = -0.5019682049751282\n",
      "Episode #37: Reward = -500, Best reward = -390, Position = 9, Epsilon = 0.08181564120552276, Alpha = 0.5\n",
      "Position without discretizing = -0.5442406535148621\n",
      "Episode #38: Reward = -500, Best reward = -390, Position = 9, Epsilon = 0.08068754016455384, Alpha = 0.5\n",
      "Position without discretizing = -0.5546364784240723\n",
      "Episode #39: Reward = -500, Best reward = -390, Position = 9, Epsilon = 0.07958800173440753, Alpha = 0.5\n",
      "Position without discretizing = -0.585239589214325\n",
      "Episode #40: Reward = -356, Best reward = -356, Position = 9, Epsilon = 0.07851561519523022, Alpha = 0.5\n",
      "Position without discretizing = 0.5093536376953125\n",
      "Episode #41: Reward = -352, Best reward = -352, Position = 9, Epsilon = 0.07746907182741372, Alpha = 0.5\n",
      "Position without discretizing = 0.508904218673706\n",
      "Episode #42: Reward = -500, Best reward = -352, Position = 9, Epsilon = 0.07644715530924512, Alpha = 0.5\n",
      "Position without discretizing = -0.0765993520617485\n",
      "Episode #43: Reward = -500, Best reward = -352, Position = 9, Epsilon = 0.07544873321858503, Alpha = 0.5\n",
      "Position without discretizing = -0.4715751111507416\n",
      "Episode #44: Reward = -500, Best reward = -352, Position = 9, Epsilon = 0.07447274948966941, Alpha = 0.5\n",
      "Position without discretizing = -0.4644186198711395\n",
      "Episode #45: Reward = -500, Best reward = -352, Position = 9, Epsilon = 0.07351821769904636, Alpha = 0.5\n",
      "Position without discretizing = -0.22041839361190796\n",
      "Episode #46: Reward = -430, Best reward = -352, Position = 9, Epsilon = 0.07258421507363202, Alpha = 0.5\n",
      "Position without discretizing = 0.509253978729248\n",
      "Episode #47: Reward = -230, Best reward = -230, Position = 9, Epsilon = 0.07166987712964505, Alpha = 0.5\n",
      "Position without discretizing = 0.5041056871414185\n",
      "Episode #48: Reward = -500, Best reward = -230, Position = 9, Epsilon = 0.0707743928643524, Alpha = 0.5\n",
      "Position without discretizing = -0.8797423839569092\n",
      "Episode #49: Reward = -500, Best reward = -230, Position = 9, Epsilon = 0.06989700043360188, Alpha = 0.5\n",
      "Position without discretizing = -0.01366797462105751\n",
      "Episode #50: Reward = -321, Best reward = -230, Position = 9, Epsilon = 0.06903698325741013, Alpha = 0.5\n",
      "Position without discretizing = 0.5024815201759338\n",
      "Episode #51: Reward = -500, Best reward = -230, Position = 9, Epsilon = 0.06819366650372385, Alpha = 0.5\n",
      "Position without discretizing = -0.404349148273468\n",
      "Episode #52: Reward = -224, Best reward = -224, Position = 9, Epsilon = 0.06736641390712486, Alpha = 0.5\n",
      "Position without discretizing = 0.5077996253967285\n",
      "Episode #53: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.06655462488490692, Alpha = 0.5\n",
      "Position without discretizing = -0.02290218509733677\n",
      "Episode #54: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.06575773191777938, Alpha = 0.5\n",
      "Position without discretizing = -0.5172913074493408\n",
      "Episode #55: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.06497519816658372, Alpha = 0.5\n",
      "Position without discretizing = 0.22801612317562103\n",
      "Episode #56: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.06420651529995462, Alpha = 0.5\n",
      "Position without discretizing = -0.5069971680641174\n",
      "Episode #57: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.06345120151091004, Alpha = 0.5\n",
      "Position without discretizing = -0.5294395685195923\n",
      "Episode #58: Reward = -441, Best reward = -224, Position = 9, Epsilon = 0.06270879970298936, Alpha = 0.5\n",
      "Position without discretizing = 0.5097591876983643\n",
      "Episode #59: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.0619788758288394, Alpha = 0.5\n",
      "Position without discretizing = -0.07498692721128464\n",
      "Episode #60: Reward = -240, Best reward = -224, Position = 9, Epsilon = 0.06126101736612706, Alpha = 0.5\n",
      "Position without discretizing = 0.5234454870223999\n",
      "Episode #61: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.06055483191737837, Alpha = 0.5\n",
      "Position without discretizing = -0.9927691221237183\n",
      "Episode #62: Reward = -230, Best reward = -224, Position = 9, Epsilon = 0.0598599459218456, Alpha = 0.5\n",
      "Position without discretizing = 0.5002179145812988\n",
      "Episode #63: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.05917600346881505, Alpha = 0.5\n",
      "Position without discretizing = -0.15026669204235077\n",
      "Episode #64: Reward = -406, Best reward = -224, Position = 9, Epsilon = 0.058502665202918205, Alpha = 0.5\n",
      "Position without discretizing = 0.503409206867218\n",
      "Episode #65: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.0578396073130169, Alpha = 0.5\n",
      "Position without discretizing = 0.0795586034655571\n",
      "Episode #66: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.05718652059712112, Alpha = 0.5\n",
      "Position without discretizing = 0.32195743918418884\n",
      "Episode #67: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.056543109596580134, Alpha = 0.5\n",
      "Position without discretizing = 0.09771065413951874\n",
      "Episode #68: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.05590909179347823, Alpha = 0.5\n",
      "Position without discretizing = 0.12416347861289978\n",
      "Episode #69: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.05528419686577808, Alpha = 0.5\n",
      "Position without discretizing = -0.5594639778137207\n",
      "Episode #70: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.05466816599529624, Alpha = 0.5\n",
      "Position without discretizing = -0.5641626715660095\n",
      "Episode #71: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.05406075122407692, Alpha = 0.5\n",
      "Position without discretizing = -0.4968624711036682\n",
      "Episode #72: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.053461714855158174, Alpha = 0.5\n",
      "Position without discretizing = -0.5038058757781982\n",
      "Episode #73: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.05287082889410615, Alpha = 0.5\n",
      "Position without discretizing = -0.5685898661613464\n",
      "Episode #74: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.05228787452803377, Alpha = 0.5\n",
      "Position without discretizing = -0.48591747879981995\n",
      "Episode #75: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.051712641639124625, Alpha = 0.5\n",
      "Position without discretizing = -0.5015463829040527\n",
      "Episode #76: Reward = -260, Best reward = -224, Position = 9, Epsilon = 0.05114492834995557, Alpha = 0.5\n",
      "Position without discretizing = 0.5175806879997253\n",
      "Episode #77: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.05058454059815572, Alpha = 0.5\n",
      "Position without discretizing = 0.05863019451498985\n",
      "Episode #78: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.050031291738159615, Alpha = 0.5\n",
      "Position without discretizing = -0.7504551410675049\n",
      "Episode #79: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.0494850021680094, Alpha = 0.49485002168009395\n",
      "Position without discretizing = -0.9278222322463989\n",
      "Episode #80: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.04894549897933879, Alpha = 0.48945498979338786\n",
      "Position without discretizing = -1.0435510873794556\n",
      "Episode #81: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.04841261562883209, Alpha = 0.4841261562883209\n",
      "Position without discretizing = -0.692118227481842\n",
      "Episode #82: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.04788619162959638, Alpha = 0.47886191629596375\n",
      "Position without discretizing = -1.0401018857955933\n",
      "Episode #83: Reward = -282, Best reward = -224, Position = 9, Epsilon = 0.04736607226101561, Alpha = 0.473660722610156\n",
      "Position without discretizing = 0.5036168694496155\n",
      "Episode #84: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.04685210829577449, Alpha = 0.46852108295774486\n",
      "Position without discretizing = -0.6208680272102356\n",
      "Episode #85: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.046344155742847, Alpha = 0.46344155742846993\n",
      "Position without discretizing = -0.5185476541519165\n",
      "Episode #86: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.045842075605341905, Alpha = 0.45842075605341903\n",
      "Position without discretizing = -0.5722193121910095\n",
      "Episode #87: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.045345733652186894, Alpha = 0.4534573365218689\n",
      "Position without discretizing = 0.2686533033847809\n",
      "Episode #88: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.044855000202712485, Alpha = 0.4485500020271248\n",
      "Position without discretizing = 0.22247213125228882\n",
      "Episode #89: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.04436974992327128, Alpha = 0.44369749923271273\n",
      "Position without discretizing = -0.24799059331417084\n",
      "Episode #90: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.043889861635094396, Alpha = 0.43889861635094396\n",
      "Position without discretizing = -0.015426693484187126\n",
      "Episode #91: Reward = -225, Best reward = -224, Position = 9, Epsilon = 0.04341521813264824, Alpha = 0.43415218132648237\n",
      "Position without discretizing = 0.5006915330886841\n",
      "Episode #92: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.04294570601181025, Alpha = 0.4294570601181025\n",
      "Position without discretizing = 0.20076924562454224\n",
      "Episode #93: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.042481215507233897, Alpha = 0.42481215507233894\n",
      "Position without discretizing = 0.29640576243400574\n",
      "Episode #94: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.04202164033831899, Alpha = 0.4202164033831899\n",
      "Position without discretizing = 0.1578218787908554\n",
      "Episode #95: Reward = -421, Best reward = -224, Position = 9, Epsilon = 0.04156687756324692, Alpha = 0.4156687756324692\n",
      "Position without discretizing = 0.5003368854522705\n",
      "Episode #96: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.041116827440579276, Alpha = 0.41116827440579273\n",
      "Position without discretizing = -0.49770045280456543\n",
      "Episode #97: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.04067139329795427, Alpha = 0.4067139329795427\n",
      "Position without discretizing = -0.6907402276992798\n",
      "Episode #98: Reward = -472, Best reward = -224, Position = 9, Epsilon = 0.040230481407448775, Alpha = 0.4023048140744877\n",
      "Position without discretizing = 0.5081915855407715\n",
      "Episode #99: Reward = -500, Best reward = -224, Position = 9, Epsilon = 0.03979400086720376, Alpha = 0.3979400086720376\n",
      "Position without discretizing = -0.41891515254974365\n",
      "\n",
      "Best episode:\n",
      "Episode #52, Best reward = -224, position = 9, Epsilon = 0.03979400086720376, Alpha = 0.3979400086720376\n",
      "Final position without discretizing = -0.41891515254974365\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.9\n",
    "gamma = 0.99\n",
    "num_episodes = 100\n",
    "\n",
    "best_reward = float('-inf')\n",
    "best_episode = None\n",
    "best_position = -1.2\n",
    "\n",
    "for i in range(num_episodes):\n",
    "    obs = env.reset()\n",
    "    total_reward = 0\n",
    "    alpha = max(0.01, min(0.5, 1.0 - math.log10((i+1)/25)))\n",
    "    epsilon = max(0.01, min(1, 0.1 * (1.0 - math.log10((i+1)/25))))\n",
    "\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        state = get_state(obs)\n",
    "        action = epsilon_greedy_policy(state, Q, epsilon)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        next_state = get_state(obs)\n",
    "        Q[state][action] = Q[state][action] + alpha * (reward + gamma * np.max(Q[next_state]) - Q[state][action])\n",
    "\n",
    "    if total_reward > best_reward:\n",
    "        best_reward = total_reward\n",
    "        best_episode = i\n",
    "        \n",
    "    if best_position < next_state[0]: \n",
    "        best_position = next_state[0]\n",
    "\n",
    "    if i % 1 == 0:\n",
    "        print(\"Episode #{}: Reward = {}, Best reward = {}, Position = {}, Epsilon = {}, Alpha = {}\".format(i, total_reward, best_reward, best_position, epsilon, alpha))\n",
    "        print(\"Position without discretizing = {}\".format(obs[0]))\n",
    "\n",
    "print(\"\\nBest episode:\")\n",
    "print(\"Episode #{}, Best reward = {}, position = {}, Epsilon = {}, Alpha = {}\".format(best_episode, best_reward, best_position, epsilon, alpha))\n",
    "print(\"Final position without discretizing = {}\".format(obs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.55331695  0.        ]\n",
      "-> (4, 5) 0 -1 [-0.5540944  -0.00077741] False\n",
      "-> (4, 5) 0 -1 [-0.5556434  -0.00154901] False\n",
      "-> (4, 5) 0 -1 [-0.5579524  -0.00230905] False\n",
      "-> (4, 5) 0 -1 [-0.5610043  -0.00305185] False\n",
      "-> (4, 5) 0 -1 [-0.5647762 -0.0037719] False\n",
      "-> (4, 5) 0 -1 [-0.56924003 -0.00446385] False\n",
      "-> (4, 5) 0 -1 [-0.57436264 -0.00512261] False\n",
      "-> (4, 5) 1 -1 [-0.579106   -0.00474335] False\n",
      "-> (4, 5) 0 -1 [-0.5844349  -0.00532897] False\n",
      "-> (4, 5) 0 -1 [-0.59031016 -0.00587523] False\n",
      "-> (4, 5) 0 -1 [-0.5966884  -0.00637823] False\n",
      "-> (4, 5) 0 -1 [-0.60352284 -0.00683444] False\n",
      "-> (3, 5) 1 -1 [-0.60976356 -0.00624073] False\n",
      "-> (3, 5) 1 -1 [-0.6153652  -0.00560167] False\n",
      "-> (3, 5) 1 -1 [-0.6202873  -0.00492208] False\n",
      "-> (3, 5) 1 -1 [-0.6244944  -0.00420704] False\n",
      "-> (3, 5) 1 -1 [-0.6279562  -0.00346183] False\n",
      "-> (3, 5) 1 -1 [-0.6306481  -0.00269187] False\n",
      "-> (3, 5) 1 -1 [-0.6325508  -0.00190273] False\n",
      "-> (3, 5) 1 -1 [-0.63365084 -0.00110006] False\n",
      "-> (3, 5) 2 -1 [-0.6329404   0.00071041] False\n",
      "-> (3, 5) 0 -1 [-6.324246e-01  5.158483e-04] False\n",
      "-> (3, 5) 1 -1 [-0.631107    0.00131762] False\n",
      "-> (3, 5) 1 -1 [-0.62899697  0.00211002] False\n",
      "-> (3, 5) 1 -1 [-0.62610954  0.0028874 ] False\n",
      "-> (3, 5) 1 -1 [-0.6224654   0.00364417] False\n",
      "-> (3, 5) 1 -1 [-0.6180905   0.00437485] False\n",
      "-> (3, 5) 0 -1 [-0.6140164   0.00407408] False\n",
      "-> (3, 5) 1 -1 [-0.6092725   0.00474393] False\n",
      "-> (3, 5) 1 -1 [-0.6038931   0.00537943] False\n",
      "-> (3, 5) 1 -1 [-0.59791726  0.00597583] False\n",
      "-> (4, 5) 0 -1 [-0.59238863  0.00552861] False\n",
      "-> (4, 5) 1 -1 [-0.58634776  0.00604088] False\n",
      "-> (4, 5) 0 -1 [-0.58083904  0.00550873] False\n",
      "-> (4, 5) 0 -1 [-0.5759031   0.00493592] False\n",
      "-> (4, 5) 2 -1 [-0.5695765  0.0063266] False\n",
      "-> (4, 5) 1 -1 [-0.56290615  0.00667034] False\n",
      "-> (4, 5) 1 -1 [-0.5559417   0.00696446] False\n",
      "-> (4, 5) 0 -1 [-0.54973507  0.00620665] False\n",
      "-> (4, 5) 0 -1 [-0.54433256  0.00540247] False\n",
      "-> (4, 5) 0 -1 [-0.5397747   0.00455788] False\n",
      "-> (4, 5) 1 -1 [-0.5350956   0.00467915] False\n",
      "-> (4, 5) 1 -1 [-0.5303302   0.00476536] False\n",
      "-> (4, 5) 0 -1 [-0.52651435  0.00381584] False\n",
      "-> (4, 5) 0 -1 [-0.52367663  0.0028377 ] False\n",
      "-> (4, 5) 0 -1 [-0.52183837  0.00183829] False\n",
      "-> (4, 5) 0 -1 [-0.52101326  0.00082509] False\n",
      "-> (4, 5) 2 -1 [-0.5192076   0.00180569] False\n",
      "-> (4, 5) 1 -1 [-0.51743484  0.00177276] False\n",
      "-> (4, 5) 0 -1 [-0.5167083   0.00072653] False\n",
      "-> (4, 5) 0 -1 [-5.1703340e-01 -3.2514014e-04] False\n",
      "-> (4, 5) 0 -1 [-0.5184078  -0.00137438] False\n",
      "-> (4, 5) 0 -1 [-0.5208211  -0.00241331] False\n",
      "-> (4, 5) 0 -1 [-0.5242553  -0.00343414] False\n",
      "-> (4, 5) 1 -1 [-0.52768445 -0.00342922] False\n",
      "-> (4, 5) 1 -1 [-0.53108305 -0.00339857] False\n",
      "-> (4, 5) 2 -1 [-0.5334255  -0.00234245] False\n",
      "-> (4, 5) 0 -1 [-0.5366942  -0.00326876] False\n",
      "-> (4, 5) 1 -1 [-0.53986484 -0.00317057] False\n",
      "-> (4, 5) 0 -1 [-0.5439134  -0.00404862] False\n",
      "-> (4, 5) 0 -1 [-0.54880977 -0.00489635] False\n",
      "-> (4, 5) 0 -1 [-0.55451727 -0.00570745] False\n",
      "-> (4, 5) 1 -1 [-0.55999315 -0.0054759 ] False\n",
      "-> (4, 5) 0 -1 [-0.5661966  -0.00620348] False\n",
      "-> (4, 5) 0 -1 [-0.5730815  -0.00688487] False\n",
      "-> (4, 5) 2 -1 [-0.5785966  -0.00551511] False\n",
      "-> (4, 5) 0 -1 [-0.58470106 -0.00610449] False\n",
      "-> (4, 5) 0 -1 [-0.59134984 -0.00664879] False\n",
      "-> (4, 5) 1 -1 [-0.597494   -0.00614415] False\n",
      "-> (4, 5) 0 -1 [-0.6040885  -0.00659446] False\n",
      "-> (3, 5) 2 -1 [-0.6090851  -0.00499664] False\n",
      "-> (3, 5) 0 -1 [-0.6144476  -0.00536249] False\n",
      "-> (3, 5) 1 -1 [-0.6191371  -0.00468953] False\n",
      "-> (3, 5) 1 -1 [-0.6231199  -0.00398276] False\n",
      "-> (3, 5) 1 -1 [-0.6263673 -0.0032474] False\n",
      "-> (3, 5) 1 -1 [-0.62885606 -0.00248878] False\n",
      "-> (3, 5) 1 -1 [-0.6305685  -0.00171241] False\n",
      "-> (3, 5) 1 -1 [-0.6314923  -0.00092383] False\n",
      "-> (3, 5) 1 -1 [-6.3162100e-01 -1.2868928e-04] False\n",
      "-> (3, 5) 2 -1 [-0.6299536   0.00166737] False\n",
      "-> (3, 5) 1 -1 [-0.6275021   0.00245157] False\n",
      "-> (3, 5) 1 -1 [-0.6242838   0.00321828] False\n",
      "-> (3, 5) 1 -1 [-0.6203218   0.00396199] False\n",
      "-> (3, 5) 1 -1 [-0.6156445   0.00467728] False\n",
      "-> (3, 5) 0 -1 [-0.6112856   0.00435888] False\n",
      "-> (3, 5) 2 -1 [-0.60527664  0.00600897] False\n",
      "-> (3, 5) 1 -1 [-0.59866124  0.00661544] False\n",
      "-> (4, 5) 2 -1 [-0.59048754  0.00817367] False\n",
      "-> (4, 6) 1 -1 [-0.5818156   0.00867197] False\n",
      "-> (4, 6) 2 -1 [-0.5717092   0.01010638] False\n",
      "-> (4, 6) 2 -1 [-0.56024325  0.01146596] False\n",
      "-> (4, 6) 2 -1 [-0.547503    0.01274024] False\n",
      "-> (4, 6) 2 -1 [-0.53358364  0.01391937] False\n",
      "-> (4, 6) 2 -1 [-0.5185894   0.01499424] False\n",
      "-> (4, 6) 2 -1 [-0.50263274  0.01595667] False\n",
      "-> (4, 6) 1 -1 [-0.48683318  0.01579953] False\n",
      "-> (4, 6) 2 -1 [-0.47030884  0.01652435] False\n",
      "-> (4, 6) 0 -1 [-0.45518246  0.01512637] False\n",
      "-> (4, 6) 0 -1 [-0.4415656   0.01361685] False\n",
      "-> (4, 6) 1 -1 [-0.4285578   0.01300779] False\n",
      "-> (4, 6) 2 -1 [-0.41525322  0.0133046 ] False\n",
      "-> (4, 6) 2 -1 [-0.401747    0.01350624] False\n",
      "-> (4, 6) 2 -1 [-0.3881344   0.01361257] False\n",
      "-> (5, 6) 2 -1 [-0.37451008  0.01362433] False\n",
      "-> (5, 6) 1 -1 [-0.361967    0.01254307] False\n",
      "-> (5, 6) 1 -1 [-0.35058922  0.01137778] False\n",
      "-> (5, 6) 2 -1 [-0.33945155  0.01113769] False\n",
      "-> (5, 6) 1 -1 [-0.32962576  0.00982577] False\n",
      "-> (5, 6) 1 -1 [-0.32117406  0.0084517 ] False\n",
      "-> (5, 6) 2 -1 [-0.31314895  0.00802512] False\n",
      "-> (5, 6) 1 -1 [-0.3065994   0.00654954] False\n",
      "-> (5, 5) 0 -1 [-0.30256483  0.00403458] False\n",
      "-> (5, 5) 1 -1 [-0.30006915  0.00249567] False\n",
      "-> (5, 5) 1 -1 [-0.2991271   0.00094205] False\n",
      "-> (5, 5) 0 -1 [-0.30074418 -0.00161709] False\n",
      "-> (5, 5) 1 -1 [-0.30391094 -0.00316674] False\n",
      "-> (5, 5) 1 -1 [-0.30860862 -0.00469768] False\n",
      "-> (5, 5) 1 -1 [-0.31480923 -0.00620062] False\n",
      "-> (5, 5) 1 -1 [-0.32247537 -0.00766614] False\n",
      "-> (5, 5) 1 -1 [-0.33156008 -0.00908469] False\n",
      "-> (5, 4) 1 -1 [-0.34200668 -0.01044662] False\n",
      "-> (5, 4) 2 -1 [-0.35274887 -0.01074218] False\n",
      "-> (5, 4) 1 -1 [-0.36471707 -0.01196819] False\n",
      "-> (5, 4) 1 -1 [-0.37783223 -0.01311519] False\n",
      "-> (5, 4) 1 -1 [-0.39200616 -0.01417393] False\n",
      "-> (5, 4) 1 -1 [-0.4071416  -0.01513543] False\n",
      "-> (4, 4) 0 -1 [-0.4241328 -0.0169912] False\n",
      "-> (4, 4) 1 -1 [-0.44185898 -0.01772618] False\n",
      "-> (4, 4) 2 -1 [-0.45919207 -0.0173331 ] False\n",
      "-> (4, 4) 1 -1 [-0.4770052  -0.01781315] False\n",
      "-> (4, 4) 1 -1 [-0.4951667  -0.01816146] False\n",
      "-> (4, 4) 1 -1 [-0.51354116 -0.01837444] False\n",
      "-> (4, 4) 0 -1 [-0.532991   -0.01944987] False\n",
      "-> (4, 4) 0 -1 [-0.5533704  -0.02037943] False\n",
      "-> (4, 4) 0 -1 [-0.57452685 -0.02115644] False\n",
      "-> (4, 4) 2 -1 [-0.59430283 -0.01977597] False\n",
      "-> (4, 4) 2 -1 [-0.6125525  -0.01824965] False\n",
      "-> (3, 4) 0 -1 [-0.6311429  -0.01859039] False\n",
      "-> (3, 4) 0 -1 [-0.6499406  -0.01879773] False\n",
      "-> (3, 4) 0 -1 [-0.6688133  -0.01887269] False\n",
      "-> (3, 4) 1 -1 [-0.686631   -0.01781771] False\n",
      "-> (3, 4) 0 -1 [-0.7042742  -0.01764314] False\n",
      "-> (3, 4) 0 -1 [-0.7216276  -0.01735345] False\n",
      "-> (3, 4) 2 -1 [-0.7365817  -0.01495407] False\n",
      "-> (3, 4) 0 -1 [-0.75104487 -0.01446319] False\n",
      "-> (3, 4) 0 -1 [-0.76493156 -0.01388667] False\n",
      "-> (3, 4) 0 -1 [-0.77816224 -0.01323071] False\n",
      "-> (3, 4) 0 -1 [-0.79066396 -0.01250173] False\n",
      "-> (3, 4) 1 -1 [-0.80137026 -0.01070626] False\n",
      "-> (2, 4) 0 -1 [-0.81122607 -0.00985585] False\n",
      "-> (2, 4) 1 -1 [-0.81918263 -0.00795655] False\n",
      "-> (2, 4) 1 -1 [-0.82520163 -0.00601899] False\n",
      "-> (2, 5) 1 -1 [-0.82925487 -0.00405322] False\n",
      "-> (2, 5) 1 -1 [-0.8313237  -0.00206882] False\n",
      "-> (2, 5) 1 -1 [-8.3139867e-01 -7.5016695e-05] False\n",
      "-> (2, 5) 1 -1 [-0.8294796   0.00191912] False\n",
      "-> (2, 5) 1 -1 [-0.825575    0.00390455] False\n",
      "-> (2, 5) 1 -1 [-0.8197029   0.00587205] False\n",
      "-> (2, 5) 2 -1 [-0.81089085  0.00881207] False\n",
      "-> (2, 6) 0 -1 [-0.80118114  0.00970973] False\n",
      "-> (2, 6) 2 -1 [-0.78862196  0.01255919] False\n",
      "-> (3, 6) 1 -1 [-0.774278    0.01434397] False\n",
      "-> (3, 6) 2 -1 [-0.75722617  0.01705179] False\n",
      "-> (3, 6) 2 -1 [-0.7375622   0.01966402] False\n",
      "-> (3, 6) 1 -1 [-0.7164014  0.0211608] False\n",
      "-> (3, 6) 2 -1 [-0.69287384  0.02352753] False\n",
      "-> (3, 7) 0 -1 [-0.6691306   0.02374322] False\n",
      "-> (3, 7) 0 -1 [-0.64533025  0.02380036] False\n",
      "-> (3, 7) 0 -1 [-0.62163705  0.02369319] False\n",
      "-> (3, 7) 1 -1 [-0.59721917  0.02441792] False\n",
      "-> (4, 7) 2 -1 [-0.57125354  0.0259656 ] False\n",
      "-> (4, 7) 0 -1 [-0.54593176  0.02532179] False\n",
      "-> (4, 7) 2 -1 [-0.5194426   0.02648916] False\n",
      "-> (4, 7) 1 -1 [-0.4929846   0.02645799] False\n",
      "-> (4, 7) 2 -1 [-0.46575588  0.02722871] False\n",
      "-> (4, 7) 2 -1 [-0.43795884  0.02779706] False\n",
      "-> (4, 7) 0 -1 [-0.41179702  0.02616181] False\n",
      "-> (4, 7) 2 -1 [-0.38545808  0.02633893] False\n",
      "-> (5, 7) 2 -1 [-0.35912582  0.02633227] False\n",
      "-> (5, 7) 2 -1 [-0.33297765  0.02614817] False\n",
      "-> (5, 7) 2 -1 [-0.30718246  0.02579517] False\n",
      "-> (5, 7) 2 -1 [-0.28189877  0.0252837 ] False\n",
      "-> (5, 7) 0 -1 [-0.25927308  0.02262568] False\n",
      "-> (5, 6) 1 -1 [-0.23842852  0.02084456] False\n",
      "-> (5, 6) 0 -1 [-0.22047122  0.0179573 ] False\n",
      "-> (5, 6) 2 -1 [-0.20348674  0.01698449] False\n",
      "-> (5, 6) 1 -1 [-0.18855071  0.01493603] False\n",
      "-> (6, 6) 0 -1 [-0.17672528  0.01182543] False\n",
      "-> (6, 6) 0 -1 [-0.16805665  0.00866863] False\n",
      "-> (6, 6) 0 -1 [-0.16257696  0.00547969] False\n",
      "-> (6, 5) 1 -1 [-0.15930575  0.0032712 ] False\n",
      "-> (6, 5) 0 -1 [-1.5925445e-01  5.1310788e-05] False\n",
      "-> (6, 5) 2 -1 [-0.1604232  -0.00116875] False\n",
      "-> (6, 5) 1 -1 [-0.16380797 -0.00338477] False\n",
      "-> (6, 5) 0 -1 [-0.1703969  -0.00658893] False\n",
      "-> (6, 5) 1 -1 [-0.17916623 -0.00876933] False\n",
      "-> (6, 4) 0 -1 [-0.19108304 -0.01191681] False\n",
      "-> (6, 4) 2 -1 [-0.20410022 -0.01301717] False\n",
      "-> (5, 4) 1 -1 [-0.21916321 -0.01506299] False\n",
      "-> (5, 4) 1 -1 [-0.23620503 -0.01704181] False\n",
      "-> (5, 4) 2 -1 [-0.254145   -0.01793997] False\n",
      "-> (5, 4) 0 -1 [-0.27489287 -0.02074786] False\n",
      "-> (5, 4) 1 -1 [-0.2973377  -0.02244485] False\n",
      "-> (5, 4) 0 -1 [-0.32235217 -0.02501446] False\n",
      "-> (5, 3) 1 -1 [-0.34878594 -0.02643378] False\n",
      "-> (5, 3) 0 -1 [-0.37747154 -0.02868559] False\n",
      "-> (5, 3) 0 -1 [-0.40821832 -0.03074678] False\n",
      "-> (4, 3) 0 -1 [-0.44081327 -0.03259496] False\n",
      "-> (4, 3) 1 -1 [-0.47402278 -0.03320948] False\n",
      "-> (4, 3) 0 -1 [-0.5086027  -0.03457994] False\n",
      "-> (4, 3) 0 -1 [-0.5442951  -0.03569237] False\n",
      "-> (4, 3) 0 -1 [-0.5808323  -0.03653724] False\n",
      "-> (4, 3) 2 -1 [-0.6159424 -0.0351101] False\n",
      "-> (3, 3) 0 -1 [-0.65136874 -0.03542635] False\n",
      "-> (3, 3) 0 -1 [-0.68686014 -0.03549137] False\n",
      "-> (3, 3) 0 -1 [-0.7221754  -0.03531528] False\n",
      "-> (3, 3) 2 -1 [-0.7550879 -0.0329125] False\n",
      "-> (3, 3) 0 -1 [-0.7874005  -0.03231256] False\n",
      "-> (3, 3) 1 -1 [-0.81793463 -0.0305342 ] False\n",
      "-> (2, 3) 1 -1 [-0.84653723 -0.02860257] False\n",
      "-> (2, 3) 1 -1 [-0.87307924 -0.02654203] False\n",
      "-> (2, 3) 2 -1 [-0.8964547  -0.02337542] False\n",
      "-> (2, 3) 0 -1 [-0.9185814  -0.02212673] False\n",
      "-> (2, 4) 1 -1 [-0.9383919  -0.01981053] False\n",
      "-> (2, 4) 1 -1 [-0.95583445 -0.01744254] False\n",
      "-> (2, 4) 1 -1 [-0.9708703  -0.01503586] False\n",
      "-> (2, 4) 1 -1 [-0.98347145 -0.01260111] False\n",
      "-> (2, 4) 0 -1 [-0.9946181  -0.01114666] False\n",
      "-> (2, 4) 2 -1 [-1.0022959 -0.0076777] False\n",
      "-> (1, 5) 1 -1 [-1.0074961  -0.00520034] False\n",
      "-> (1, 5) 1 -1 [-1.0102142  -0.00271805] False\n",
      "-> (1, 5) 1 -1 [-1.0104476e+00 -2.3342589e-04] False\n",
      "-> (1, 5) 0 -1 [-1.0091963  0.0012514] False\n",
      "-> (1, 5) 1 -1 [-1.0054611   0.00373517] False\n",
      "-> (1, 5) 2 -1 [-0.9982455  0.0072156] False\n",
      "-> (2, 5) 2 -1 [-0.98755676  0.01068869] False\n",
      "-> (2, 6) 2 -1 [-0.973408    0.01414878] False\n",
      "-> (2, 6) 1 -1 [-0.95682025  0.01658777] False\n",
      "-> (2, 6) 0 -1 [-0.93882376  0.01799644] False\n",
      "-> (2, 6) 1 -1 [-0.91845834  0.02036547] False\n",
      "-> (2, 6) 1 -1 [-0.895777    0.02268132] False\n",
      "-> (2, 6) 0 -1 [-0.8718492   0.02392779] False\n",
      "-> (2, 7) 1 -1 [-0.8457594   0.02608979] False\n",
      "-> (2, 7) 0 -1 [-0.8186124   0.02714701] False\n",
      "-> (2, 7) 1 -1 [-0.7895305   0.02908187] False\n",
      "-> (3, 7) 2 -1 [-0.75765914  0.03187141] False\n",
      "-> (3, 7) 0 -1 [-0.725173    0.03248612] False\n",
      "-> (3, 7) 0 -1 [-0.69226557  0.03290746] False\n",
      "-> (3, 7) 0 -1 [-0.65914637  0.03311916] False\n",
      "-> (3, 7) 0 -1 [-0.6260384   0.03310798] False\n",
      "-> (3, 7) 1 -1 [-0.5921742   0.03386424] False\n",
      "-> (4, 7) 2 -1 [-0.55679923  0.03537494] False\n",
      "-> (4, 7) 2 -1 [-0.5201757   0.03662353] False\n",
      "-> (4, 7) 2 -1 [-0.48257783  0.03759786] False\n",
      "-> (4, 7) 2 -1 [-0.44428682  0.03829098] False\n",
      "-> (4, 7) 2 -1 [-0.4055851   0.03870174] False\n",
      "-> (4, 7) 2 -1 [-0.3667501   0.03883501] False\n",
      "-> (5, 7) 2 -1 [-0.32804853  0.03870158] False\n",
      "-> (5, 7) 2 -1 [-0.28973088  0.03831764] False\n",
      "-> (5, 7) 2 -1 [-0.25202686  0.03770403] False\n",
      "-> (5, 7) 2 -1 [-0.21514165  0.0368852 ] False\n",
      "-> (5, 7) 2 -1 [-0.17925355  0.03588809] False\n",
      "-> (6, 7) 1 -1 [-0.14551261  0.03374095] False\n",
      "-> (6, 7) 1 -1 [-0.11403721  0.03147539] False\n",
      "-> (6, 7) 1 -1 [-0.08491693  0.02912028] False\n",
      "-> (6, 7) 1 -1 [-0.05821598  0.02670096] False\n",
      "-> (6, 7) 1 -1 [-0.03397699  0.02423899] False\n",
      "-> (6, 7) 1 -1 [-0.01222502  0.02175197] False\n",
      "-> (6, 6) 2 -1 [0.00802863 0.02025365] False\n",
      "-> (7, 6) 0 -1 [0.024783   0.01675437] False\n",
      "-> (7, 6) 1 -1 [0.03904428 0.01426128] False\n",
      "-> (7, 6) 1 -1 [0.05082269 0.01177841] False\n",
      "-> (7, 6) 1 -1 [0.0601301  0.00930741] False\n",
      "-> (7, 6) 1 -1 [0.06697807 0.00684798] False\n",
      "-> (7, 5) 0 -1 [0.07037635 0.00339828] False\n",
      "-> (7, 5) 0 -1 [ 7.033014e-02 -4.621159e-05] False\n",
      "-> (7, 5) 0 -1 [ 0.06683937 -0.00349077] False\n",
      "-> (7, 5) 0 -1 [ 0.05989869 -0.00694068] False\n",
      "-> (7, 5) 0 -1 [ 0.04949826 -0.01040043] False\n",
      "-> (7, 4) 2 -1 [ 0.03762535 -0.01187291] False\n",
      "-> (7, 4) 1 -1 [ 0.02326835 -0.014357  ] False\n",
      "-> (7, 4) 1 -1 [ 0.00641743 -0.01685091] False\n",
      "-> (7, 4) 1 -1 [-0.01293302 -0.01935045] False\n",
      "-> (6, 4) 0 -1 [-0.03578159 -0.02284857] False\n",
      "-> (6, 4) 0 -1 [-0.06211577 -0.02633418] False\n",
      "-> (6, 3) 0 -1 [-0.09190667 -0.0297909 ] False\n",
      "-> (6, 3) 1 -1 [-0.12410314 -0.03219647] False\n",
      "-> (6, 3) 1 -1 [-0.15862834 -0.0345252 ] False\n",
      "-> (6, 3) 1 -1 [-0.19537576 -0.03674741] False\n",
      "-> (6, 3) 1 -1 [-0.23420589 -0.03883014] False\n",
      "-> (5, 3) 2 -1 [-0.2739439  -0.03973802] False\n",
      "-> (5, 2) 0 -1 [-0.31638414 -0.04244022] False\n",
      "-> (5, 2) 2 -1 [-0.3592803  -0.04289616] False\n",
      "-> (5, 2) 2 -1 [-0.40235952 -0.04307923] False\n",
      "-> (4, 2) 0 -1 [-0.44732815 -0.04496861] False\n",
      "-> (4, 2) 0 -1 [-0.4938638  -0.04653566] False\n",
      "-> (4, 2) 0 -1 [-0.54162216 -0.04775838] False\n",
      "-> (4, 2) 0 -1 [-0.5902454  -0.04862327] False\n",
      "-> (4, 2) 0 -1 [-0.63937217 -0.04912674] False\n",
      "-> (3, 2) 1 -1 [-0.687648   -0.04827579] False\n",
      "-> (3, 2) 2 -1 [-0.7337425 -0.0460945] False\n",
      "-> (3, 2) 1 -1 [-0.7783632  -0.04462076] False\n",
      "-> (3, 2) 1 -1 [-0.82125396 -0.04289069] False\n",
      "-> (2, 2) 0 -1 [-0.8631973  -0.04194336] False\n",
      "-> (2, 2) 0 -1 [-0.90401196 -0.04081466] False\n",
      "-> (2, 2) 2 -1 [-0.9415538  -0.03754179] False\n",
      "-> (2, 3) 0 -1 [-0.9777201 -0.0361663] False\n",
      "-> (2, 3) 1 -1 [-1.0114405  -0.03372041] False\n",
      "-> (1, 3) 0 -1 [-1.0436752  -0.03223478] False\n",
      "-> (1, 3) 1 -1 [-1.0734102  -0.02973492] False\n",
      "-> (1, 3) 1 -1 [-1.1006528  -0.02724264] False\n",
      "-> (1, 3) 1 -1 [-1.1254275  -0.02477472] False\n",
      "-> (1, 3) 0 -1 [-1.1487708  -0.02334326] False\n",
      "-> (1, 3) 0 -1 [-1.1707292  -0.02195843] False\n",
      "-> (1, 4) 0 -1 [-1.1913574  -0.02062815] False\n",
      "-> (1, 4) 1 -1 [-1.2  0. ] False\n",
      "-> (0, 5) 2 -1 [-1.1967582  0.0032419] False\n",
      "-> (1, 5) 1 -1 [-1.1912637   0.00549445] False\n",
      "-> (1, 5) 1 -1 [-1.1834991   0.00776456] False\n",
      "-> (1, 5) 0 -1 [-1.1744406   0.00905846] False\n",
      "-> (1, 6) 1 -1 [-1.1630621   0.01137851] False\n",
      "-> (1, 6) 1 -1 [-1.1493331  0.013729 ] False\n",
      "-> (1, 6) 0 -1 [-1.1342206   0.01511256] False\n",
      "-> (1, 6) 1 -1 [-1.1166928   0.01752784] False\n",
      "-> (1, 6) 2 -1 [-1.095719    0.02097371] False\n",
      "-> (1, 6) 2 -1 [-1.0712718   0.02444727] False\n",
      "-> (1, 7) 1 -1 [-1.044331    0.02694075] False\n",
      "-> (1, 7) 2 -1 [-1.0138904   0.03044066] False\n",
      "-> (1, 7) 1 -1 [-0.98096216  0.03292819] False\n",
      "-> (2, 7) 0 -1 [-0.94658315  0.03437899] False\n",
      "-> (2, 7) 1 -1 [-0.9098172   0.03676597] False\n",
      "-> (2, 7) 2 -1 [-0.8697606   0.04005663] False\n",
      "-> (2, 8) 2 -1 [-0.8265498   0.04321073] False\n",
      "-> (2, 8) 0 -1 [-0.7823671   0.04418272] False\n",
      "-> (3, 8) 2 -1 [-0.73543274  0.04693434] False\n",
      "-> (3, 8) 2 -1 [-0.6860145  0.0494183] False\n",
      "-> (3, 8) 2 -1 [-0.6344257   0.05158878] False\n",
      "-> (3, 8) 2 -1 [-0.58102095  0.05340476] False\n",
      "-> (4, 8) 2 -1 [-0.52618766  0.0548333 ] False\n",
      "-> (4, 9) 2 -1 [-0.47033492  0.05585271] False\n",
      "-> (4, 9) 1 -1 [-0.41488     0.05545493] False\n",
      "-> (4, 9) 2 -1 [-0.35922608  0.05565392] False\n",
      "-> (5, 9) 2 -1 [-0.30375558  0.05547048] False\n",
      "-> (5, 9) 2 -1 [-0.24881697  0.05493862] False\n",
      "-> (5, 9) 2 -1 [-0.1947136   0.05410336] False\n",
      "-> (6, 8) 2 -1 [-0.14169571  0.0530179 ] False\n",
      "-> (6, 8) 2 -1 [-0.08995532  0.05174039] False\n",
      "-> (6, 8) 1 -1 [-0.04062445  0.04933087] False\n",
      "-> (6, 8) 2 -1 [0.00722496 0.04784942] False\n",
      "-> (7, 8) 2 -1 [0.05357497 0.04635   ] False\n",
      "-> (7, 8) 2 -1 [0.09845719 0.04488222] False\n",
      "-> (7, 8) 2 -1 [0.14194769 0.04349049] False\n",
      "-> (7, 8) 2 -1 [0.18416144 0.04221376] False\n",
      "-> (7, 8) 1 -1 [0.22424714 0.0400857 ] False\n",
      "-> (8, 8) 2 -1 [0.26337755 0.03913041] False\n",
      "-> (8, 8) 1 -1 [0.3007486  0.03737104] False\n",
      "-> (8, 7) 0 -1 [0.33557    0.03482141] False\n",
      "-> (8, 7) 1 -1 [0.36905482 0.0334848 ] False\n",
      "-> (8, 7) 2 -1 [0.40242162 0.0333668 ] False\n",
      "-> (9, 7) 1 -1 [0.43489948 0.03247786] False\n",
      "-> (9, 7) 2 -1 [0.4677199  0.03282044] False\n",
      "-> (9, 7) 1 -1 [0.5001232  0.03240331] True\n",
      "Reward: -362\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "print(obs)\n",
    "done = False\n",
    "total_reward = 0\n",
    "while not done:\n",
    "    state = get_state(obs)\n",
    "    action = epsilon_greedy_policy(state, Q, 0.5)\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "    print('->', state, action, reward, obs, done)\n",
    "print(f\"Reward: {total_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importación del modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('model.pkl', 'wb') as f:\n",
    "#     pickle.dump(Q, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
